{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "Exl7lIH58-Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Peaks Normalization and Log Transformation"
      ],
      "metadata": {
        "id": "kLLFvQC_JwJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open('Peaks.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader) # skip header\n",
        "    for row in reader:\n",
        "        float_row = []\n",
        "        for x in row[1:]:\n",
        "            if x == '':\n",
        "                float_row.append(np.nan)\n",
        "            else:\n",
        "                float_row.append(float(x))\n",
        "        data.append(float_row)\n",
        "\n",
        "# Replace NaN with 0\n",
        "data = [np.nan_to_num(x) for x in data]\n",
        "\n",
        "data=pd.DataFrame(data)\n",
        "#Log transform\n",
        "def log_transform(x):\n",
        "    return np.log(x) if x > 0 else x\n",
        "\n",
        "data = data.applymap(log_transform)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "normalized_data = scaler.fit_transform(data)\n",
        "\n",
        "data = pd.DataFrame(normalized_data)\n",
        "\n",
        "data = data.iloc[91:]\n",
        "timesteps = 29\n",
        "n_features = data.shape[1]"
      ],
      "metadata": {
        "id": "IwNYoD5E8-GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "xjNgwsTQ6jZD",
        "outputId": "e3c340c6-9d9c-4085-88d2-e75ff1b4fa24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6   \\\n",
              "91   0.069168  0.176509  0.564049  0.817757  0.347033  0.860707  0.920590   \n",
              "92   0.217291  0.264445  0.407301  0.686477  0.244306  0.565762  0.913335   \n",
              "93   0.132179  0.378657  0.436799  0.797944  0.297506  0.912097  0.870094   \n",
              "94   0.281155  0.488094  0.655198  0.579835  0.271399  0.689883  0.973338   \n",
              "95   0.293265  0.693835  0.615815  0.801268  0.244306  0.908731  0.924119   \n",
              "96   0.393838  0.559225  0.668665  0.697370  0.186847  0.825343  0.863056   \n",
              "97   0.393838  0.488094  0.596639  0.323996  0.562466  0.448258  0.867776   \n",
              "98   0.361874  0.456751  0.528768  0.579835  0.516727  0.385492  0.901923   \n",
              "99   0.256296  0.698982  0.514749  0.319080  0.535374  0.457664  0.887710   \n",
              "100  0.350891  0.578835  0.721592  0.522807  0.457692  0.689883  0.870094   \n",
              "101  0.434329  0.597749  0.572432  0.679161  0.322696  0.948594  0.909604   \n",
              "102  0.293265  0.578835  0.588722  0.704578  0.271399  0.759288  0.891877   \n",
              "103  0.281155  0.661865  0.505141  0.436425  0.201649  0.543935  0.915174   \n",
              "104  0.383343  0.704080  0.615815  0.488984  0.310211  0.526219  0.982635   \n",
              "105  0.293265  0.616014  0.706694  0.467358  0.334968  0.419646  0.901923   \n",
              "106  0.268834  0.693835  0.612048  0.467358  0.426247  0.395338  0.913335   \n",
              "107  0.444101  0.738458  0.752648  0.449778  0.553548  0.561424  0.876887   \n",
              "108  0.085454  0.698982  0.684923  0.133199  0.393363  0.400234  0.850735   \n",
              "109  0.491032  0.864880  0.619549  0.304210  0.415452  0.467005  0.881288   \n",
              "110  0.230532  0.552524  0.856144  0.372105  0.347033  0.250604  0.905801   \n",
              "111  0.305171  0.572378  0.637745  0.551654  0.426247  0.530669  0.895958   \n",
              "112  0.281155  0.678090  0.596639  0.567837  0.426247  0.503747  0.942467   \n",
              "113  0.316880  0.503101  0.555498  0.653204  0.244306  0.673970  0.895958   \n",
              "114  0.230532  0.747887  0.675243  0.263648  0.124385  0.335173  0.959242   \n",
              "115  0.383343  0.714131  0.537865  0.309186  0.055966  0.499207  0.885593   \n",
              "116  0.305171  0.672736  0.604413  0.418391  0.230367  0.250604  0.889805   \n",
              "117  0.328400  0.524846  0.453567  0.319080  0.297506  0.194965  0.909604   \n",
              "118  0.176012  0.733681  0.634167  0.216347  0.216151  0.194965  0.000000   \n",
              "119  0.243531  0.531901  0.665338  0.172707  0.156295  0.131030  0.000000   \n",
              "\n",
              "           7         8         9         10  \n",
              "91   1.000000  0.990861  0.533145  0.253642  \n",
              "92   0.972659  0.986428  0.626912  0.253642  \n",
              "93   0.905314  0.980558  0.726903  0.512032  \n",
              "94   0.852383  0.981880  0.574103  0.220795  \n",
              "95   0.847351  0.947854  0.750823  0.220795  \n",
              "96   0.814523  0.931104  0.613895  0.285536  \n",
              "97   0.776043  0.903574  0.665251  0.253642  \n",
              "98   0.871451  0.901507  0.702567  0.186937  \n",
              "99   0.847351  0.921163  0.808893  0.316532  \n",
              "100  0.875975  0.967484  0.990041  0.404602  \n",
              "101  0.866834  0.972415  0.918267  0.376021  \n",
              "102  0.826009  0.951803  0.853673  0.346679  \n",
              "103  0.857304  0.939678  0.417675  0.346679  \n",
              "104  0.847351  0.968907  0.600756  0.285536  \n",
              "105  0.782933  0.931981  0.626912  0.459628  \n",
              "106  0.826009  0.960934  0.587493  0.486142  \n",
              "107  0.857304  0.988975  0.750823  0.486142  \n",
              "108  0.866834  0.970318  0.808893  0.459628  \n",
              "109  0.866834  0.946249  0.626912  0.537327  \n",
              "110  0.808552  0.967484  0.652587  0.459628  \n",
              "111  0.746143  0.903574  0.505159  0.486142  \n",
              "112  0.913037  0.966049  0.533145  0.459628  \n",
              "113  0.789618  0.921163  0.808893  0.376021  \n",
              "114  0.866834  0.990234  0.864648  0.152005  \n",
              "115  0.847351  0.924843  0.340347  0.486142  \n",
              "116  0.802417  0.928448  0.774341  0.459628  \n",
              "117  0.875975  0.942171  0.308178  0.253642  \n",
              "118  0.000000  0.000000  0.928749  0.253642  \n",
              "119  0.000000  0.000000  0.990041  0.376021  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cade475f-4216-4404-9564-d06b5e3fd9d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>0.069168</td>\n",
              "      <td>0.176509</td>\n",
              "      <td>0.564049</td>\n",
              "      <td>0.817757</td>\n",
              "      <td>0.347033</td>\n",
              "      <td>0.860707</td>\n",
              "      <td>0.920590</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.990861</td>\n",
              "      <td>0.533145</td>\n",
              "      <td>0.253642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.217291</td>\n",
              "      <td>0.264445</td>\n",
              "      <td>0.407301</td>\n",
              "      <td>0.686477</td>\n",
              "      <td>0.244306</td>\n",
              "      <td>0.565762</td>\n",
              "      <td>0.913335</td>\n",
              "      <td>0.972659</td>\n",
              "      <td>0.986428</td>\n",
              "      <td>0.626912</td>\n",
              "      <td>0.253642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.132179</td>\n",
              "      <td>0.378657</td>\n",
              "      <td>0.436799</td>\n",
              "      <td>0.797944</td>\n",
              "      <td>0.297506</td>\n",
              "      <td>0.912097</td>\n",
              "      <td>0.870094</td>\n",
              "      <td>0.905314</td>\n",
              "      <td>0.980558</td>\n",
              "      <td>0.726903</td>\n",
              "      <td>0.512032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.281155</td>\n",
              "      <td>0.488094</td>\n",
              "      <td>0.655198</td>\n",
              "      <td>0.579835</td>\n",
              "      <td>0.271399</td>\n",
              "      <td>0.689883</td>\n",
              "      <td>0.973338</td>\n",
              "      <td>0.852383</td>\n",
              "      <td>0.981880</td>\n",
              "      <td>0.574103</td>\n",
              "      <td>0.220795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.293265</td>\n",
              "      <td>0.693835</td>\n",
              "      <td>0.615815</td>\n",
              "      <td>0.801268</td>\n",
              "      <td>0.244306</td>\n",
              "      <td>0.908731</td>\n",
              "      <td>0.924119</td>\n",
              "      <td>0.847351</td>\n",
              "      <td>0.947854</td>\n",
              "      <td>0.750823</td>\n",
              "      <td>0.220795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.393838</td>\n",
              "      <td>0.559225</td>\n",
              "      <td>0.668665</td>\n",
              "      <td>0.697370</td>\n",
              "      <td>0.186847</td>\n",
              "      <td>0.825343</td>\n",
              "      <td>0.863056</td>\n",
              "      <td>0.814523</td>\n",
              "      <td>0.931104</td>\n",
              "      <td>0.613895</td>\n",
              "      <td>0.285536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.393838</td>\n",
              "      <td>0.488094</td>\n",
              "      <td>0.596639</td>\n",
              "      <td>0.323996</td>\n",
              "      <td>0.562466</td>\n",
              "      <td>0.448258</td>\n",
              "      <td>0.867776</td>\n",
              "      <td>0.776043</td>\n",
              "      <td>0.903574</td>\n",
              "      <td>0.665251</td>\n",
              "      <td>0.253642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.361874</td>\n",
              "      <td>0.456751</td>\n",
              "      <td>0.528768</td>\n",
              "      <td>0.579835</td>\n",
              "      <td>0.516727</td>\n",
              "      <td>0.385492</td>\n",
              "      <td>0.901923</td>\n",
              "      <td>0.871451</td>\n",
              "      <td>0.901507</td>\n",
              "      <td>0.702567</td>\n",
              "      <td>0.186937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.256296</td>\n",
              "      <td>0.698982</td>\n",
              "      <td>0.514749</td>\n",
              "      <td>0.319080</td>\n",
              "      <td>0.535374</td>\n",
              "      <td>0.457664</td>\n",
              "      <td>0.887710</td>\n",
              "      <td>0.847351</td>\n",
              "      <td>0.921163</td>\n",
              "      <td>0.808893</td>\n",
              "      <td>0.316532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.350891</td>\n",
              "      <td>0.578835</td>\n",
              "      <td>0.721592</td>\n",
              "      <td>0.522807</td>\n",
              "      <td>0.457692</td>\n",
              "      <td>0.689883</td>\n",
              "      <td>0.870094</td>\n",
              "      <td>0.875975</td>\n",
              "      <td>0.967484</td>\n",
              "      <td>0.990041</td>\n",
              "      <td>0.404602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.434329</td>\n",
              "      <td>0.597749</td>\n",
              "      <td>0.572432</td>\n",
              "      <td>0.679161</td>\n",
              "      <td>0.322696</td>\n",
              "      <td>0.948594</td>\n",
              "      <td>0.909604</td>\n",
              "      <td>0.866834</td>\n",
              "      <td>0.972415</td>\n",
              "      <td>0.918267</td>\n",
              "      <td>0.376021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.293265</td>\n",
              "      <td>0.578835</td>\n",
              "      <td>0.588722</td>\n",
              "      <td>0.704578</td>\n",
              "      <td>0.271399</td>\n",
              "      <td>0.759288</td>\n",
              "      <td>0.891877</td>\n",
              "      <td>0.826009</td>\n",
              "      <td>0.951803</td>\n",
              "      <td>0.853673</td>\n",
              "      <td>0.346679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.281155</td>\n",
              "      <td>0.661865</td>\n",
              "      <td>0.505141</td>\n",
              "      <td>0.436425</td>\n",
              "      <td>0.201649</td>\n",
              "      <td>0.543935</td>\n",
              "      <td>0.915174</td>\n",
              "      <td>0.857304</td>\n",
              "      <td>0.939678</td>\n",
              "      <td>0.417675</td>\n",
              "      <td>0.346679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.383343</td>\n",
              "      <td>0.704080</td>\n",
              "      <td>0.615815</td>\n",
              "      <td>0.488984</td>\n",
              "      <td>0.310211</td>\n",
              "      <td>0.526219</td>\n",
              "      <td>0.982635</td>\n",
              "      <td>0.847351</td>\n",
              "      <td>0.968907</td>\n",
              "      <td>0.600756</td>\n",
              "      <td>0.285536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.293265</td>\n",
              "      <td>0.616014</td>\n",
              "      <td>0.706694</td>\n",
              "      <td>0.467358</td>\n",
              "      <td>0.334968</td>\n",
              "      <td>0.419646</td>\n",
              "      <td>0.901923</td>\n",
              "      <td>0.782933</td>\n",
              "      <td>0.931981</td>\n",
              "      <td>0.626912</td>\n",
              "      <td>0.459628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.268834</td>\n",
              "      <td>0.693835</td>\n",
              "      <td>0.612048</td>\n",
              "      <td>0.467358</td>\n",
              "      <td>0.426247</td>\n",
              "      <td>0.395338</td>\n",
              "      <td>0.913335</td>\n",
              "      <td>0.826009</td>\n",
              "      <td>0.960934</td>\n",
              "      <td>0.587493</td>\n",
              "      <td>0.486142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0.444101</td>\n",
              "      <td>0.738458</td>\n",
              "      <td>0.752648</td>\n",
              "      <td>0.449778</td>\n",
              "      <td>0.553548</td>\n",
              "      <td>0.561424</td>\n",
              "      <td>0.876887</td>\n",
              "      <td>0.857304</td>\n",
              "      <td>0.988975</td>\n",
              "      <td>0.750823</td>\n",
              "      <td>0.486142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.085454</td>\n",
              "      <td>0.698982</td>\n",
              "      <td>0.684923</td>\n",
              "      <td>0.133199</td>\n",
              "      <td>0.393363</td>\n",
              "      <td>0.400234</td>\n",
              "      <td>0.850735</td>\n",
              "      <td>0.866834</td>\n",
              "      <td>0.970318</td>\n",
              "      <td>0.808893</td>\n",
              "      <td>0.459628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.491032</td>\n",
              "      <td>0.864880</td>\n",
              "      <td>0.619549</td>\n",
              "      <td>0.304210</td>\n",
              "      <td>0.415452</td>\n",
              "      <td>0.467005</td>\n",
              "      <td>0.881288</td>\n",
              "      <td>0.866834</td>\n",
              "      <td>0.946249</td>\n",
              "      <td>0.626912</td>\n",
              "      <td>0.537327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.230532</td>\n",
              "      <td>0.552524</td>\n",
              "      <td>0.856144</td>\n",
              "      <td>0.372105</td>\n",
              "      <td>0.347033</td>\n",
              "      <td>0.250604</td>\n",
              "      <td>0.905801</td>\n",
              "      <td>0.808552</td>\n",
              "      <td>0.967484</td>\n",
              "      <td>0.652587</td>\n",
              "      <td>0.459628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0.305171</td>\n",
              "      <td>0.572378</td>\n",
              "      <td>0.637745</td>\n",
              "      <td>0.551654</td>\n",
              "      <td>0.426247</td>\n",
              "      <td>0.530669</td>\n",
              "      <td>0.895958</td>\n",
              "      <td>0.746143</td>\n",
              "      <td>0.903574</td>\n",
              "      <td>0.505159</td>\n",
              "      <td>0.486142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0.281155</td>\n",
              "      <td>0.678090</td>\n",
              "      <td>0.596639</td>\n",
              "      <td>0.567837</td>\n",
              "      <td>0.426247</td>\n",
              "      <td>0.503747</td>\n",
              "      <td>0.942467</td>\n",
              "      <td>0.913037</td>\n",
              "      <td>0.966049</td>\n",
              "      <td>0.533145</td>\n",
              "      <td>0.459628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>0.316880</td>\n",
              "      <td>0.503101</td>\n",
              "      <td>0.555498</td>\n",
              "      <td>0.653204</td>\n",
              "      <td>0.244306</td>\n",
              "      <td>0.673970</td>\n",
              "      <td>0.895958</td>\n",
              "      <td>0.789618</td>\n",
              "      <td>0.921163</td>\n",
              "      <td>0.808893</td>\n",
              "      <td>0.376021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0.230532</td>\n",
              "      <td>0.747887</td>\n",
              "      <td>0.675243</td>\n",
              "      <td>0.263648</td>\n",
              "      <td>0.124385</td>\n",
              "      <td>0.335173</td>\n",
              "      <td>0.959242</td>\n",
              "      <td>0.866834</td>\n",
              "      <td>0.990234</td>\n",
              "      <td>0.864648</td>\n",
              "      <td>0.152005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.383343</td>\n",
              "      <td>0.714131</td>\n",
              "      <td>0.537865</td>\n",
              "      <td>0.309186</td>\n",
              "      <td>0.055966</td>\n",
              "      <td>0.499207</td>\n",
              "      <td>0.885593</td>\n",
              "      <td>0.847351</td>\n",
              "      <td>0.924843</td>\n",
              "      <td>0.340347</td>\n",
              "      <td>0.486142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.305171</td>\n",
              "      <td>0.672736</td>\n",
              "      <td>0.604413</td>\n",
              "      <td>0.418391</td>\n",
              "      <td>0.230367</td>\n",
              "      <td>0.250604</td>\n",
              "      <td>0.889805</td>\n",
              "      <td>0.802417</td>\n",
              "      <td>0.928448</td>\n",
              "      <td>0.774341</td>\n",
              "      <td>0.459628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.328400</td>\n",
              "      <td>0.524846</td>\n",
              "      <td>0.453567</td>\n",
              "      <td>0.319080</td>\n",
              "      <td>0.297506</td>\n",
              "      <td>0.194965</td>\n",
              "      <td>0.909604</td>\n",
              "      <td>0.875975</td>\n",
              "      <td>0.942171</td>\n",
              "      <td>0.308178</td>\n",
              "      <td>0.253642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0.176012</td>\n",
              "      <td>0.733681</td>\n",
              "      <td>0.634167</td>\n",
              "      <td>0.216347</td>\n",
              "      <td>0.216151</td>\n",
              "      <td>0.194965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.928749</td>\n",
              "      <td>0.253642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.243531</td>\n",
              "      <td>0.531901</td>\n",
              "      <td>0.665338</td>\n",
              "      <td>0.172707</td>\n",
              "      <td>0.156295</td>\n",
              "      <td>0.131030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.990041</td>\n",
              "      <td>0.376021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cade475f-4216-4404-9564-d06b5e3fd9d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cade475f-4216-4404-9564-d06b5e3fd9d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cade475f-4216-4404-9564-d06b5e3fd9d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-193b5777-701d-4a1c-90ca-1a76fa013ae1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-193b5777-701d-4a1c-90ca-1a76fa013ae1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-193b5777-701d-4a1c-90ca-1a76fa013ae1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(timesteps, 1))\n",
        "x = LSTM(30)(inputs)\n",
        "x = Dense(15)(x)\n",
        "x = Dense(10)(x)\n",
        "x = Dense(5)(x)\n",
        "encoded = Dense(1)(x)\n",
        "\n",
        "# decoded = Dense(16)(encoded)\n",
        "# decoded = Dense(32)(decoded)\n",
        "# decoded = Dense(61)(decoded)\n",
        "# decoded = Reshape((61, 1))(decoded)\n",
        "# decoded = LSTM(1, return_sequences=True)(decoded)\n",
        "decoded = Dense(timesteps)(encoded)\n",
        "decoded = Reshape((timesteps, 1))(decoded)\n",
        "decoded = LSTM(30, return_sequences=True)(decoded)\n",
        "decoded = Dense(15)(decoded)\n",
        "decoded = Dense(10)(decoded)\n",
        "decoded = Dense(5)(decoded)\n",
        "decoded = Dense(1)(decoded)\n",
        "\n",
        "latent_space_model = Model(inputs, encoded)\n",
        "autoencoder = Model(inputs, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n"
      ],
      "metadata": {
        "id": "w7lTISX0Q4y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEd2GJ9JFFiB",
        "outputId": "a3b708c8-bf47-4074-d8c7-2ad48e4331b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 29, 1)]           0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 30)                3840      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 15)                465       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                160       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 29)                58        \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 29, 1)             0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 29, 30)            3840      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 29, 15)            465       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 29, 10)            160       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 29, 5)             55        \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 29, 1)             6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,110\n",
            "Trainable params: 9,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_features):\n",
        "    print(f'Training on column: {i+1}/{n_features}')\n",
        "    x_train = data.iloc[:, i].values.reshape(-1, timesteps, 1)\n",
        "\n",
        "    autoencoder.fit(x_train, x_train, epochs=50, batch_size=16,verbose=0)\n",
        "\n",
        "# Save model weights\n",
        "autoencoder.save_weights('autoencoder_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU2s4TjC898v",
        "outputId": "6105906c-c968-407c-cd66-64b6a1febea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on column: 1/11\n",
            "Training on column: 2/11\n",
            "Training on column: 3/11\n",
            "Training on column: 4/11\n",
            "Training on column: 5/11\n",
            "Training on column: 6/11\n",
            "Training on column: 7/11\n",
            "Training on column: 8/11\n",
            "Training on column: 9/11\n",
            "Training on column: 10/11\n",
            "Training on column: 11/11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sequence_and_latent_space(input_sequence):\n",
        "    input_sequence = np.array(input_sequence)\n",
        "    input_sequence = input_sequence.reshape(1, -1, 1)\n",
        "    print(input_sequence.shape)\n",
        "    predicted_sequence = autoencoder.predict(input_sequence)\n",
        "    latent_space_output = latent_space_model.predict(input_sequence)\n",
        "    return predicted_sequence.reshape(-1), latent_space_output[0][0]\n",
        "\n",
        "def denormalize(normalized_value, min_val, max_val):\n",
        "    return normalized_value * (max_val - min_val) + min_val\n",
        "\n",
        "# Denormalize the input sequence\n",
        "column_to_predict = 1\n",
        "input_sequence = data.iloc[:, column_to_predict].values.tolist()\n",
        "min_input = scaler.data_min_[column_to_predict]\n",
        "max_input = scaler.data_max_[column_to_predict]\n",
        "denormalized_input_sequence = [denormalize(val, min_input, max_input) for val in input_sequence]\n",
        "\n",
        "# Denormalize the predictions and latent space output\n",
        "min_output = scaler.data_min_[0]\n",
        "max_output = scaler.data_max_[0]\n",
        "predictions, latent_space_output = predict_sequence_and_latent_space(input_sequence)\n",
        "denormalized_predictions = [denormalize(val, min_output, max_output) for val in predictions]\n",
        "denormalized_latent_output = denormalize(latent_space_output, min_output, max_output)\n",
        "\n",
        "print(\"Original Sequence:\")\n",
        "print(denormalized_input_sequence)\n",
        "\n",
        "print(\"Predicted Sequence:\")\n",
        "print(denormalized_predictions)\n",
        "\n",
        "print(\"Latent Space Output:\")\n",
        "print(denormalized_latent_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDfTEUtPEbum",
        "outputId": "913a2243-999d-41cb-f0de-4e0cd0f79947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 29, 1)\n",
            "1/1 [==============================] - 1s 977ms/step\n",
            "1/1 [==============================] - 0s 458ms/step\n",
            "Original Sequence:\n",
            "[3.6635616461296467, 3.828641396489095, 4.04305126783455, 4.248495242049359, 4.634728988229636, 4.382026634673881, 4.248495242049359, 4.189654742026425, 4.6443908991413725, 4.418840607796599, 4.454347296253507, 4.418840607796599, 4.574710978503383, 4.653960350157523, 4.48863636973214, 4.634728988229636, 4.718498871295095, 4.6443908991413725, 4.955827057601262, 4.3694478524670215, 4.406719247264253, 4.605170185988092, 4.276666119016055, 4.736198448394496, 4.672828834461906, 4.595119850134591, 4.31748811353631, 4.709530201312334, 4.330733340286331]\n",
            "Predicted Sequence:\n",
            "[4.168145919576295, 4.177501211030522, 4.183358522586396, 4.1833929773602545, 4.179357519817443, 4.177236342585821, 4.177701503067565, 4.180446357982271, 4.180529444891148, 4.176645941735608, 4.168087527358816, 4.160307900251452, 4.160305291953553, 4.162489951790488, 4.165509982133528, 4.169418137911145, 4.174548281254397, 4.182560131013406, 4.189701103759428, 4.196549736794169, 4.1991341393187716, 4.204191418598138, 4.199661352048917, 4.188847685514636, 4.179453311661246, 4.1678591750847, 4.155941104736838, 4.129884208726804, 4.099050972362709]\n",
            "Latent Space Output:\n",
            "4.4350860679879105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the predicted sequence back to a DataFrame\n",
        "predictions_df = pd.DataFrame(denormalized_predictions, columns=['Predicted Sequence'])\n",
        "\n",
        "# Get the original DataFrame\n",
        "original_df = pd.DataFrame(denormalized_input_sequence, columns = ['Original Sequence'])\n",
        "\n",
        "# Get the column to predict (column_to_predict) and the corresponding column name\n",
        "# column_name = original_df.columns[column_to_predict]\n",
        "\n",
        "# Append the predicted sequence to the original DataFrame\n",
        "original_df['Predicted Sequence'] = predictions_df\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "original_df.to_csv('predicted_sequences.csv', index=False)\n",
        "\n",
        "print(\"Original Sequence and Predicted Sequence saved to 'predicted_sequences.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emK_djJgca9O",
        "outputId": "b8427c74-ae32-41fd-a0ec-f75a4b08b9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sequence and Predicted Sequence saved to 'predicted_sequences.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_log_transform(x):\n",
        "    return np.exp(x) if x > 0 else x\n",
        "\n",
        "# Apply the inverse log transform to the data\n",
        "latent_space_op = inverse_log_transform(denormalized_latent_output)\n",
        "print(latent_space_op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4YmlSGAOGao",
        "outputId": "6c7fbc9c-268c-46b2-d585-8f6f2f8d480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.35938521839228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the data and scaler already defined before this point\n",
        "num_columns = 11  # Total number of columns in your data\n",
        "\n",
        "def predict_and_get_latent_output(input_sequence, column_idx):\n",
        "    input_sequence = np.array(input_sequence)\n",
        "    input_sequence = input_sequence.reshape(1, -1, 1)\n",
        "    predicted_sequence = autoencoder.predict(input_sequence)\n",
        "    latent_space_output = latent_space_model.predict(input_sequence)\n",
        "    return predicted_sequence.reshape(-1), latent_space_output.reshape(-1)\n",
        "\n",
        "# Create an array to store the latent_space_op values for each column\n",
        "latent_space_op_array = []\n",
        "\n",
        "# Loop over each column\n",
        "for column_idx in range(num_columns):\n",
        "    # Denormalize the input sequence\n",
        "    input_sequence = data.iloc[:, column_idx].values.tolist()\n",
        "    min_input = scaler.data_min_[column_idx]\n",
        "    max_input = scaler.data_max_[column_idx]\n",
        "    denormalized_input_sequence = [denormalize(val, min_input, max_input) for val in input_sequence]\n",
        "\n",
        "    # Denormalize the predictions and latent space output for this column\n",
        "    min_output = scaler.data_min_[0]  # Assuming the latent space output is in the first column\n",
        "    max_output = scaler.data_max_[0]\n",
        "    predictions, latent_space_output = predict_and_get_latent_output(input_sequence, column_idx)\n",
        "    denormalized_predictions = [denormalize(val, min_output, max_output) for val in predictions]\n",
        "    denormalized_latent_output = denormalize(latent_space_output, min_output, max_output)\n",
        "\n",
        "\n",
        "    inverse_log_transformed_predictions = []\n",
        "    inverse_log_transformed_input_sequence = []\n",
        "\n",
        "    # Loop over the denormalized predictions and input sequences\n",
        "    for prediction, input_val in zip(denormalized_predictions, denormalized_input_sequence):\n",
        "        # Apply inverse log transform to the values and store them in the arrays\n",
        "        inverse_log_transformed_predictions.append(inverse_log_transform(prediction))\n",
        "        inverse_log_transformed_input_sequence.append(inverse_log_transform(input_val))\n",
        "\n",
        "    # Print the inverse log transform results\n",
        "\n",
        "    # Apply the inverse log transform to the data for this column\n",
        "    latent_space_op = inverse_log_transform(denormalized_latent_output)\n",
        "    latent_space_op_array.append(latent_space_op)\n",
        "\n",
        "# Print the results or perform any further operations with latent_space_op_array\n",
        "print(\"Inverse Log Transformed Predictions:\")\n",
        "print(inverse_log_transformed_predictions)\n",
        "\n",
        "print(\"Inverse Log Transformed Input Sequence:\")\n",
        "print(inverse_log_transformed_input_sequence)\n",
        "print(\"Latent Space Output for each column:\")\n",
        "\n",
        "print(latent_space_op_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bXo2q61Gwa2",
        "outputId": "63345a8e-a0de-4c7d-aec4-32f06a7c1863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Inverse Log Transformed Predictions:\n",
            "[64.60784354291344, 65.24047122991783, 65.6559245126413, 65.68141812111253, 65.41204045835487, 65.28849233896649, 65.33912159496933, 65.56377100768103, 65.60321166835725, 65.35092039161276, 64.77462613523885, 64.22288562181078, 64.1961540433114, 64.33418317643007, 64.50816689690086, 64.75685868745694, 65.08277498187392, 65.63483650316655, 66.11835764752517, 66.5941999547977, 66.73825833134086, 67.10309311175291, 66.78409182890303, 66.0177114611008, 65.38591145273583, 64.62262576181489, 63.86113313897262, 62.168707188236475, 60.17843191242208]\n",
            "Inverse Log Transformed Input Sequence:\n",
            "[34.00000000000001, 34.00000000000001, 42.99999999999998, 33.0, 33.0, 34.99999999999999, 34.00000000000001, 32.0, 36.0, 38.99999999999998, 37.99999999999999, 36.99999999999999, 36.99999999999999, 34.99999999999999, 41.00000000000001, 42.00000000000001, 42.00000000000001, 41.00000000000001, 43.99999999999997, 41.00000000000001, 42.00000000000001, 41.00000000000001, 37.99999999999999, 31.0, 42.00000000000001, 41.00000000000001, 34.00000000000001, 34.00000000000001, 37.99999999999999]\n",
            "Latent Space Output for each column:\n",
            "[array([91.83612], dtype=float32), array([84.3594], dtype=float32), array([83.94637], dtype=float32), array([93.41439], dtype=float32), array([93.89263], dtype=float32), array([94.99288], dtype=float32), array([93.80005], dtype=float32), array([94.20094], dtype=float32), array([93.58863], dtype=float32), array([78.774895], dtype=float32), array([90.243965], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_space_op_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YvDz4d0JFHD",
        "outputId": "988bbb60-f8c6-431e-e3c5-72226d5fa1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([91.83612], dtype=float32),\n",
              " array([84.3594], dtype=float32),\n",
              " array([83.94637], dtype=float32),\n",
              " array([93.41439], dtype=float32),\n",
              " array([93.89263], dtype=float32),\n",
              " array([94.99288], dtype=float32),\n",
              " array([93.80005], dtype=float32),\n",
              " array([94.20094], dtype=float32),\n",
              " array([93.58863], dtype=float32),\n",
              " array([78.774895], dtype=float32),\n",
              " array([90.243965], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inverse_log_transformed_predictions = []\n",
        "# inverse_log_transformed_input_sequence = []\n",
        "\n",
        "# # Loop over the denormalized predictions and input sequences\n",
        "# for prediction, input_val in zip(denormalized_predictions, denormalized_input_sequence):\n",
        "#     # Apply inverse log transform to the values and store them in the arrays\n",
        "#     inverse_log_transformed_predictions.append(inverse_log_transform(prediction))\n",
        "#     inverse_log_transformed_input_sequence.append(inverse_log_transform(input_val))\n",
        "\n",
        "# Create a list of headers for the CSV file\n",
        "headers = ['denormalized_predictions', 'denormalized_input_sequence']\n",
        "\n",
        "# Combine the lists into a single array\n",
        "combined_data = np.column_stack((denormalized_predictions, denormalized_input_sequence))\n",
        "\n",
        "# Save the data to a CSV file\n",
        "output_file = 'output_data.csv'\n",
        "with open(output_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    # Write the headers\n",
        "    writer.writerow(headers)\n",
        "    # Write the data below each header\n",
        "    writer.writerows(combined_data)\n",
        "\n",
        "print(\"Data saved to\", output_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s04nfnfKZDfu",
        "outputId": "69f1ea1f-a340-4d18-8feb-0832eb6e00e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to output_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [['Latent Space Output for each column:']]\n",
        "for item in latent_space_op_array:\n",
        "    data.append([item[0]])\n",
        "\n",
        "# Write data to CSV file\n",
        "csv_filename = 'latent_space_output.csv'\n",
        "with open(csv_filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "VVECPBBmLgUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AVGFreq"
      ],
      "metadata": {
        "id": "8t4pHXRyJ3Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuSbow-aLSxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}